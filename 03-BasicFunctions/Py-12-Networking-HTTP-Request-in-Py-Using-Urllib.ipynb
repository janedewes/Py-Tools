{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using urllib in Python\n",
    "\n",
    "- Since HTTP is so common, we have a library that does all the socket work for us and makes web pages look like a file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# Ex1:\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "# Data\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "# Ex2:\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "# Data\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "\n",
    "# Create a dict\n",
    "counts = dict()\n",
    "\n",
    "# Split the lines of this file in separate words (decode, because it comes from an extenal source)\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    \n",
    "    # Count how many times a word appears in the text\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "\n",
    "print(counts)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading Web Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>The First Page</h1>\n",
      "<p>\n",
      "If you like, you can switch to the\n",
      "<a href=\"http://www.dr-chuck.com/page2.htm\">\n",
      "Second Page</a>.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "# Ex1: \n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "# Open data\n",
    "fhand = urllib.request.urlopen('http://www.dr-chuck.com/page1.htm')\n",
    "\n",
    "# For each line in the file make a decode and strip\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# Ex2:\n",
    "\n",
    "import urllib.request\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
